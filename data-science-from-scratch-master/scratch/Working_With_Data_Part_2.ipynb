{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33062465",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scratch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(title)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscratch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inverse_normal_cdf\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_normal\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a random draw from a standard normal distribution\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scratch'"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bucketize(point: float, bucket_size: float) -> float:\n",
    "    \"\"\"Floor the point to the next lower multiple of bucket_size\"\"\"\n",
    "    return bucket_size * math.floor(point / bucket_size)\n",
    "\n",
    "def make_histogram(points: List[float], bucket_size: float) -> Dict[float, int]:\n",
    "    \"\"\"Buckets the points and counts how many in each bucket\"\"\"\n",
    "    return Counter(bucketize(point, bucket_size) for point in points)\n",
    "\n",
    "def plot_histogram(points: List[float], bucket_size: float, title: str = \"\"):\n",
    "    histogram = make_histogram(points, bucket_size)\n",
    "    plt.bar(histogram.keys(), histogram.values(), width=bucket_size)\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "import random\n",
    "from scratch.probability import inverse_normal_cdf\n",
    "\n",
    "def random_normal() -> float:\n",
    "    \"\"\"Returns a random draw from a standard normal distribution\"\"\"\n",
    "    return inverse_normal_cdf(random.random())\n",
    "\n",
    "xs = [random_normal() for _ in range(1000)]\n",
    "ys1 = [ x + random_normal() / 2 for x in xs]\n",
    "ys2 = [-x + random_normal() / 2 for x in xs]\n",
    "\n",
    "plt.scatter(xs, ys1, marker='.', color='black', label='ys1')\n",
    "plt.scatter(xs, ys2, marker='.', color='gray',  label='ys2')\n",
    "plt.xlabel('xs')\n",
    "plt.ylabel('ys')\n",
    "plt.legend(loc=9)\n",
    "plt.title(\"Very Different Joint Distributions\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.savefig('im/working_scatter.png')\n",
    "plt.gca().clear()\n",
    "\n",
    "\n",
    "from scratch.statistics import correlation\n",
    "\n",
    "\n",
    "assert 0.89 < correlation(xs, ys1) < 0.91\n",
    "assert -0.91 < correlation(xs, ys2) < -0.89\n",
    "\n",
    "from scratch.linear_algebra import Matrix, Vector, make_matrix\n",
    "\n",
    "def correlation_matrix(data: List[Vector]) -> Matrix:\n",
    "    \"\"\"\n",
    "    Returns the len(data) x len(data) matrix whose (i, j)-th entry\n",
    "    is the correlation between data[i] and data[j]\n",
    "    \"\"\"\n",
    "    def correlation_ij(i: int, j: int) -> float:\n",
    "        return correlation(data[i], data[j])\n",
    "\n",
    "    return make_matrix(len(data), len(data), correlation_ij)\n",
    "\n",
    "\n",
    "vectors = [xs, ys1, ys2]\n",
    "assert correlation_matrix(vectors) == [\n",
    "    [correlation(xs,  xs), correlation(xs,  ys1), correlation(xs,  ys2)],\n",
    "    [correlation(ys1, xs), correlation(ys1, ys1), correlation(ys1, ys2)],\n",
    "    [correlation(ys2, xs), correlation(ys2, ys1), correlation(ys2, ys2)],\n",
    "]\n",
    "\n",
    "import datetime\n",
    "\n",
    "stock_price = {'closing_price': 102.06,\n",
    "               'date': datetime.date(2014, 8, 29),\n",
    "               'symbol': 'AAPL'}\n",
    "\n",
    "# oops, typo\n",
    "stock_price['cosing_price'] = 103.06\n",
    "\n",
    "prices: Dict[datetime.date, float] = {}\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "class StockPrice(NamedTuple):\n",
    "    symbol: str\n",
    "    date: datetime.date\n",
    "    closing_price: float\n",
    "\n",
    "    def is_high_tech(self) -> bool:\n",
    "        \"\"\"It's a class, so we can add methods too\"\"\"\n",
    "        return self.symbol in ['MSFT', 'GOOG', 'FB', 'AMZN', 'AAPL']\n",
    "\n",
    "price = StockPrice('MSFT', datetime.date(2018, 12, 14), 106.03)\n",
    "\n",
    "assert price.symbol == 'MSFT'\n",
    "assert price.closing_price == 106.03\n",
    "assert price.is_high_tech()\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def parse_row(row: List[str]) -> StockPrice:\n",
    "    symbol, date, closing_price = row\n",
    "    return StockPrice(symbol=symbol,\n",
    "                      date=parse(date).date(),\n",
    "                      closing_price=float(closing_price))\n",
    "\n",
    "# Now test our function\n",
    "stock = parse_row([\"MSFT\", \"2018-12-14\", \"106.03\"])\n",
    "\n",
    "assert stock.symbol == \"MSFT\"\n",
    "assert stock.date == datetime.date(2018, 12, 14)\n",
    "assert stock.closing_price == 106.03\n",
    "\n",
    "from typing import Optional\n",
    "import re\n",
    "\n",
    "def try_parse_row(row: List[str]) -> Optional[StockPrice]:\n",
    "    symbol, date_, closing_price_ = row\n",
    "\n",
    "    # Stock symbol should be all capital letters\n",
    "    if not re.match(r\"^[A-Z]+$\", symbol):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        date = parse(date_).date()\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        closing_price = float(closing_price_)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    return StockPrice(symbol, date, closing_price)\n",
    "\n",
    "# Should return None for errors\n",
    "assert try_parse_row([\"MSFT0\", \"2018-12-14\", \"106.03\"]) is None\n",
    "assert try_parse_row([\"MSFT\", \"2018-12--14\", \"106.03\"]) is None\n",
    "assert try_parse_row([\"MSFT\", \"2018-12-14\", \"x\"]) is None\n",
    "\n",
    "# But should return same as before if data is good.\n",
    "assert try_parse_row([\"MSFT\", \"2018-12-14\", \"106.03\"]) == stock\n",
    "\n",
    "\n",
    "from dateutil.parser import parse\n",
    "import csv\n",
    "\n",
    "with open(\"stocks.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    rows = [[row['Symbol'], row['Date'], row['Close']]\n",
    "            for row in reader]\n",
    "\n",
    "# skip header\n",
    "maybe_data = [try_parse_row(row) for row in rows]\n",
    "\n",
    "# Make sure they all loaded successfully:\n",
    "assert maybe_data\n",
    "assert all(sp is not None for sp in maybe_data)\n",
    "\n",
    "# This is just to make mypy happy\n",
    "data = [sp for sp in maybe_data if sp is not None]\n",
    "\n",
    "max_aapl_price = max(stock_price.closing_price\n",
    "                     for stock_price in data\n",
    "                     if stock_price.symbol == \"AAPL\")\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "max_prices: Dict[str, float] = defaultdict(lambda: float('-inf'))\n",
    "\n",
    "for sp in data:\n",
    "    symbol, closing_price = sp.symbol, sp.closing_price\n",
    "    if closing_price > max_prices[symbol]:\n",
    "        max_prices[symbol] = closing_price\n",
    "\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "# Collect the prices by symbol\n",
    "prices: Dict[str, List[StockPrice]] = defaultdict(list)\n",
    "\n",
    "for sp in data:\n",
    "    prices[sp.symbol].append(sp)\n",
    "\n",
    "# Order the prices by date\n",
    "prices = {symbol: sorted(symbol_prices)\n",
    "          for symbol, symbol_prices in prices.items()}\n",
    "\n",
    "def pct_change(yesterday: StockPrice, today: StockPrice) -> float:\n",
    "    return today.closing_price / yesterday.closing_price - 1\n",
    "\n",
    "class DailyChange(NamedTuple):\n",
    "    symbol: str\n",
    "    date: datetime.date\n",
    "    pct_change: float\n",
    "\n",
    "def day_over_day_changes(prices: List[StockPrice]) -> List[DailyChange]:\n",
    "    \"\"\"\n",
    "    Assumes prices are for one stock and are in order\n",
    "    \"\"\"\n",
    "    return [DailyChange(symbol=today.symbol,\n",
    "                        date=today.date,\n",
    "                        pct_change=pct_change(yesterday, today))\n",
    "            for yesterday, today in zip(prices, prices[1:])]\n",
    "\n",
    "all_changes = [change\n",
    "               for symbol_prices in prices.values()\n",
    "               for change in day_over_day_changes(symbol_prices)]\n",
    "\n",
    "max_change = max(all_changes, key=lambda change: change.pct_change)\n",
    "# see, e.g. http://news.cnet.com/2100-1001-202143.html\n",
    "assert max_change.symbol == 'AAPL'\n",
    "assert max_change.date == datetime.date(1997, 8, 6)\n",
    "assert 0.33 < max_change.pct_change < 0.34\n",
    "\n",
    "min_change = min(all_changes, key=lambda change: change.pct_change)\n",
    "# see, e.g. http://money.cnn.com/2000/09/29/markets/techwrap/\n",
    "assert min_change.symbol == 'AAPL'\n",
    "assert min_change.date == datetime.date(2000, 9, 29)\n",
    "assert -0.52 < min_change.pct_change < -0.51\n",
    "\n",
    "changes_by_month: List[DailyChange] = {month: [] for month in range(1, 13)}\n",
    "\n",
    "for change in all_changes:\n",
    "    changes_by_month[change.date.month].append(change)\n",
    "\n",
    "avg_daily_change = {\n",
    "    month: sum(change.pct_change for change in changes) / len(changes)\n",
    "    for month, changes in changes_by_month.items()\n",
    "}\n",
    "\n",
    "# October is the best month\n",
    "assert avg_daily_change[10] == max(avg_daily_change.values())\n",
    "\n",
    "from scratch.linear_algebra import distance\n",
    "\n",
    "a_to_b = distance([63, 150], [67, 160])        # 10.77\n",
    "a_to_c = distance([63, 150], [70, 171])        # 22.14\n",
    "b_to_c = distance([67, 160], [70, 171])        # 11.40\n",
    "\n",
    "a_to_b = distance([160, 150], [170.2, 160])    # 14.28\n",
    "a_to_c = distance([160, 150], [177.8, 171])    # 27.53\n",
    "b_to_c = distance([170.2, 160], [177.8, 171])  # 13.37\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from scratch.linear_algebra import vector_mean\n",
    "from scratch.statistics import standard_deviation\n",
    "\n",
    "def scale(data: List[Vector]) -> Tuple[Vector, Vector]:\n",
    "    \"\"\"returns the means and standard deviations for each position\"\"\"\n",
    "    dim = len(data[0])\n",
    "\n",
    "    means = vector_mean(data)\n",
    "    stdevs = [standard_deviation([vector[i] for vector in data])\n",
    "              for i in range(dim)]\n",
    "\n",
    "    return means, stdevs\n",
    "\n",
    "vectors = [[-3, -1, 1], [-1, 0, 1], [1, 1, 1]]\n",
    "means, stdevs = scale(vectors)\n",
    "assert means == [-1, 0, 1]\n",
    "assert stdevs == [2, 1, 0]\n",
    "\n",
    "def rescale(data: List[Vector]) -> List[Vector]:\n",
    "    \"\"\"\n",
    "    Rescales the input data so that each position has\n",
    "    mean 0 and standard deviation 1. (Leaves a position\n",
    "    as is if its standard deviation is 0.)\n",
    "    \"\"\"\n",
    "    dim = len(data[0])\n",
    "    means, stdevs = scale(data)\n",
    "\n",
    "    # Make a copy of each vector\n",
    "    rescaled = [v[:] for v in data]\n",
    "\n",
    "    for v in rescaled:\n",
    "        for i in range(dim):\n",
    "            if stdevs[i] > 0:\n",
    "                v[i] = (v[i] - means[i]) / stdevs[i]\n",
    "\n",
    "    return rescaled\n",
    "\n",
    "means, stdevs = scale(rescale(vectors))\n",
    "assert means == [0, 0, 1]\n",
    "assert stdevs == [1, 1, 0]\n",
    "\n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "pca_data = [\n",
    "[20.9666776351559,-13.1138080189357],\n",
    "[22.7719907680008,-19.8890894944696],\n",
    "[25.6687103160153,-11.9956004517219],\n",
    "[18.0019794950564,-18.1989191165133],\n",
    "[21.3967402102156,-10.8893126308196],\n",
    "[0.443696899177716,-19.7221132386308],\n",
    "[29.9198322142127,-14.0958668502427],\n",
    "[19.0805843080126,-13.7888747608312],\n",
    "[16.4685063521314,-11.2612927034291],\n",
    "[21.4597664701884,-12.4740034586705],\n",
    "[3.87655283720532,-17.575162461771],\n",
    "[34.5713920556787,-10.705185165378],\n",
    "[13.3732115747722,-16.7270274494424],\n",
    "[20.7281704141919,-8.81165591556553],\n",
    "[24.839851437942,-12.1240962157419],\n",
    "[20.3019544741252,-12.8725060780898],\n",
    "[21.9021426929599,-17.3225432396452],\n",
    "[23.2285885715486,-12.2676568419045],\n",
    "[28.5749111681851,-13.2616470619453],\n",
    "[29.2957424128701,-14.6299928678996],\n",
    "[15.2495527798625,-18.4649714274207],\n",
    "[26.5567257400476,-9.19794350561966],\n",
    "[30.1934232346361,-12.6272709845971],\n",
    "[36.8267446011057,-7.25409849336718],\n",
    "[32.157416823084,-10.4729534347553],\n",
    "[5.85964365291694,-22.6573731626132],\n",
    "[25.7426190674693,-14.8055803854566],\n",
    "[16.237602636139,-16.5920595763719],\n",
    "[14.7408608850568,-20.0537715298403],\n",
    "[6.85907008242544,-18.3965586884781],\n",
    "[26.5918329233128,-8.92664811750842],\n",
    "[-11.2216019958228,-27.0519081982856],\n",
    "[8.93593745011035,-20.8261235122575],\n",
    "[24.4481258671796,-18.0324012215159],\n",
    "[2.82048515404903,-22.4208457598703],\n",
    "[30.8803004755948,-11.455358009593],\n",
    "[15.4586738236098,-11.1242825084309],\n",
    "[28.5332537090494,-14.7898744423126],\n",
    "[40.4830293441052,-2.41946428697183],\n",
    "[15.7563759125684,-13.5771266003795],\n",
    "[19.3635588851727,-20.6224770470434],\n",
    "[13.4212840786467,-19.0238227375766],\n",
    "[7.77570680426702,-16.6385739839089],\n",
    "[21.4865983854408,-15.290799330002],\n",
    "[12.6392705930724,-23.6433305964301],\n",
    "[12.4746151388128,-17.9720169566614],\n",
    "[23.4572410437998,-14.602080545086],\n",
    "[13.6878189833565,-18.9687408182414],\n",
    "[15.4077465943441,-14.5352487124086],\n",
    "[20.3356581548895,-10.0883159703702],\n",
    "[20.7093833689359,-12.6939091236766],\n",
    "[11.1032293684441,-14.1383848928755],\n",
    "[17.5048321498308,-9.2338593361801],\n",
    "[16.3303688220188,-15.1054735529158],\n",
    "[26.6929062710726,-13.306030567991],\n",
    "[34.4985678099711,-9.86199941278607],\n",
    "[39.1374291499406,-10.5621430853401],\n",
    "[21.9088956482146,-9.95198845621849],\n",
    "[22.2367457578087,-17.2200123442707],\n",
    "[10.0032784145577,-19.3557700653426],\n",
    "[14.045833906665,-15.871937521131],\n",
    "[15.5640911917607,-18.3396956121887],\n",
    "[24.4771926581586,-14.8715313479137],\n",
    "[26.533415556629,-14.693883922494],\n",
    "[12.8722580202544,-21.2750596021509],\n",
    "[24.4768291376862,-15.9592080959207],\n",
    "[18.2230748567433,-14.6541444069985],\n",
    "[4.1902148367447,-20.6144032528762],\n",
    "[12.4332594022086,-16.6079789231489],\n",
    "[20.5483758651873,-18.8512560786321],\n",
    "[17.8180560451358,-12.5451990696752],\n",
    "[11.0071081078049,-20.3938092335862],\n",
    "[8.30560561422449,-22.9503944138682],\n",
    "[33.9857852657284,-4.8371294974382],\n",
    "[17.4376502239652,-14.5095976075022],\n",
    "[29.0379635148943,-14.8461553663227],\n",
    "[29.1344666599319,-7.70862921632672],\n",
    "[32.9730697624544,-15.5839178785654],\n",
    "[13.4211493998212,-20.150199857584],\n",
    "[11.380538260355,-12.8619410359766],\n",
    "[28.672631499186,-8.51866271785711],\n",
    "[16.4296061111902,-23.3326051279759],\n",
    "[25.7168371582585,-13.8899296143829],\n",
    "[13.3185154732595,-17.8959160024249],\n",
    "[3.60832478605376,-25.4023343597712],\n",
    "[39.5445949652652,-11.466377647931],\n",
    "[25.1693484426101,-12.2752652925707],\n",
    "[25.2884257196471,-7.06710309184533],\n",
    "[6.77665715793125,-22.3947299635571],\n",
    "[20.1844223778907,-16.0427471125407],\n",
    "[25.5506805272535,-9.33856532270204],\n",
    "[25.1495682602477,-7.17350567090738],\n",
    "[15.6978431006492,-17.5979197162642],\n",
    "[37.42780451491,-10.843637288504],\n",
    "[22.974620174842,-10.6171162611686],\n",
    "[34.6327117468934,-9.26182440487384],\n",
    "[34.7042513789061,-6.9630753351114],\n",
    "[15.6563953929008,-17.2196961218915],\n",
    "[25.2049825789225,-14.1592086208169]\n",
    "]\n",
    "\n",
    "from scratch.linear_algebra import subtract\n",
    "\n",
    "def de_mean(data: List[Vector]) -> List[Vector]:\n",
    "    \"\"\"Recenters the data to have mean 0 in every dimension\"\"\"\n",
    "    mean = vector_mean(data)\n",
    "    return [subtract(vector, mean) for vector in data]\n",
    "\n",
    "from scratch.linear_algebra import magnitude\n",
    "\n",
    "def direction(w: Vector) -> Vector:\n",
    "    mag = magnitude(w)\n",
    "    return [w_i / mag for w_i in w]\n",
    "\n",
    "from scratch.linear_algebra import dot\n",
    "\n",
    "def directional_variance(data: List[Vector], w: Vector) -> float:\n",
    "    \"\"\"\n",
    "    Returns the variance of x in the direction of w\n",
    "    \"\"\"\n",
    "    w_dir = direction(w)\n",
    "    return sum(dot(v, w_dir) ** 2 for v in data)\n",
    "\n",
    "def directional_variance_gradient(data: List[Vector], w: Vector) -> Vector:\n",
    "    \"\"\"\n",
    "    The gradient of directional variance with respect to w\n",
    "    \"\"\"\n",
    "    w_dir = direction(w)\n",
    "    return [sum(2 * dot(v, w_dir) * v[i] for v in data)\n",
    "            for i in range(len(w))]\n",
    "\n",
    "from scratch.gradient_descent import gradient_step\n",
    "\n",
    "def first_principal_component(data: List[Vector],\n",
    "                              n: int = 100,\n",
    "                              step_size: float = 0.1) -> Vector:\n",
    "    # Start with a random guess\n",
    "    guess = [1.0 for _ in data[0]]\n",
    "\n",
    "    with tqdm.trange(n) as t:\n",
    "        for _ in t:\n",
    "            dv = directional_variance(data, guess)\n",
    "            gradient = directional_variance_gradient(data, guess)\n",
    "            guess = gradient_step(guess, gradient, step_size)\n",
    "            t.set_description(f\"dv: {dv:.3f}\")\n",
    "\n",
    "    return direction(guess)\n",
    "\n",
    "from scratch.linear_algebra import scalar_multiply\n",
    "\n",
    "def project(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"return the projection of v onto the direction w\"\"\"\n",
    "    projection_length = dot(v, w)\n",
    "    return scalar_multiply(projection_length, w)\n",
    "\n",
    "from scratch.linear_algebra import subtract\n",
    "\n",
    "def remove_projection_from_vector(v: Vector, w: Vector) -> Vector:\n",
    "    \"\"\"projects v onto w and subtracts the result from v\"\"\"\n",
    "    return subtract(v, project(v, w))\n",
    "\n",
    "def remove_projection(data: List[Vector], w: Vector) -> List[Vector]:\n",
    "    return [remove_projection_from_vector(v, w) for v in data]\n",
    "\n",
    "def pca(data: List[Vector], num_components: int) -> List[Vector]:\n",
    "    components: List[Vector] = []\n",
    "    for _ in range(num_components):\n",
    "        component = first_principal_component(data)\n",
    "        components.append(component)\n",
    "        data = remove_projection(data, component)\n",
    "\n",
    "    return components\n",
    "\n",
    "def transform_vector(v: Vector, components: List[Vector]) -> Vector:\n",
    "    return [dot(v, w) for w in components]\n",
    "\n",
    "def transform(data: List[Vector], components: List[Vector]) -> List[Vector]:\n",
    "    return [transform_vector(v, components) for v in data]\n",
    "\n",
    "def main():\n",
    "\n",
    "    # I don't know why this is necessary\n",
    "    plt.gca().clear()\n",
    "    plt.close()\n",
    "\n",
    "    import random\n",
    "    from scratch.probability import inverse_normal_cdf\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    # uniform between -100 and 100\n",
    "    uniform = [200 * random.random() - 100 for _ in range(10000)]\n",
    "\n",
    "    # normal distribution with mean 0, standard deviation 57\n",
    "    normal = [57 * inverse_normal_cdf(random.random())\n",
    "              for _ in range(10000)]\n",
    "\n",
    "    plot_histogram(uniform, 10, \"Uniform Histogram\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.savefig('im/working_histogram_uniform.png')\n",
    "    plt.gca().clear()\n",
    "    plt.close()\n",
    "\n",
    "    plot_histogram(normal, 10, \"Normal Histogram\")\n",
    "\n",
    "\n",
    "    plt.savefig('im/working_histogram_normal.png')\n",
    "    plt.gca().clear()\n",
    "\n",
    "    from scratch.statistics import correlation\n",
    "\n",
    "    print(correlation(xs, ys1))      # about 0.9\n",
    "    print(correlation(xs, ys2))      # about -0.9\n",
    "\n",
    "\n",
    "\n",
    "    from typing import List\n",
    "\n",
    "    # Just some random data to show off correlation scatterplots\n",
    "    num_points = 100\n",
    "\n",
    "    def random_row() -> List[float]:\n",
    "       row = [0.0, 0, 0, 0]\n",
    "       row[0] = random_normal()\n",
    "       row[1] = -5 * row[0] + random_normal()\n",
    "       row[2] = row[0] + row[1] + 5 * random_normal()\n",
    "       row[3] = 6 if row[2] > -2 else 0\n",
    "       return row\n",
    "\n",
    "    random.seed(0)\n",
    "    # each row has 4 points, but really we want the columns\n",
    "    corr_rows = [random_row() for _ in range(num_points)]\n",
    "\n",
    "    corr_data = [list(col) for col in zip(*corr_rows)]\n",
    "\n",
    "    # corr_data is a list of four 100-d vectors\n",
    "    num_vectors = len(corr_data)\n",
    "    fig, ax = plt.subplots(num_vectors, num_vectors)\n",
    "\n",
    "    for i in range(num_vectors):\n",
    "        for j in range(num_vectors):\n",
    "\n",
    "            # Scatter column_j on the x-axis vs column_i on the y-axis,\n",
    "            if i != j: ax[i][j].scatter(corr_data[j], corr_data[i])\n",
    "\n",
    "            # unless i == j, in which case show the series name.\n",
    "            else: ax[i][j].annotate(\"series \" + str(i), (0.5, 0.5),\n",
    "                                    xycoords='axes fraction',\n",
    "                                    ha=\"center\", va=\"center\")\n",
    "\n",
    "            # Then hide axis labels except left and bottom charts\n",
    "            if i < num_vectors - 1: ax[i][j].xaxis.set_visible(False)\n",
    "            if j > 0: ax[i][j].yaxis.set_visible(False)\n",
    "\n",
    "    # Fix the bottom right and top left axis labels, which are wrong because\n",
    "    # their charts only have text in them\n",
    "    ax[-1][-1].set_xlim(ax[0][-1].get_xlim())\n",
    "    ax[0][0].set_ylim(ax[0][1].get_ylim())\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    plt.savefig('im/working_scatterplot_matrix.png')\n",
    "    plt.gca().clear()\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "\n",
    "    import csv\n",
    "\n",
    "    data: List[StockPrice] = []\n",
    "\n",
    "    with open(\"comma_delimited_stock_prices.csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            maybe_stock = try_parse_row(row)\n",
    "            if maybe_stock is None:\n",
    "                print(f\"skipping invalid row: {row}\")\n",
    "            else:\n",
    "                data.append(maybe_stock)\n",
    "\n",
    "    from typing import List\n",
    "\n",
    "    def primes_up_to(n: int) -> List[int]:\n",
    "        primes = [2]\n",
    "\n",
    "        with tqdm.trange(3, n) as t:\n",
    "            for i in t:\n",
    "                # i is prime if no smaller prime divides it.\n",
    "                i_is_prime = not any(i % p == 0 for p in primes)\n",
    "                if i_is_prime:\n",
    "                    primes.append(i)\n",
    "\n",
    "                t.set_description(f\"{len(primes)} primes\")\n",
    "\n",
    "        return primes\n",
    "\n",
    "    my_primes = primes_up_to(100_000)\n",
    "\n",
    "\n",
    "\n",
    "    de_meaned = de_mean(pca_data)\n",
    "    fpc = first_principal_component(de_meaned)\n",
    "    assert 0.923 < fpc[0] < 0.925\n",
    "    assert 0.382 < fpc[1] < 0.384\n",
    "\n",
    "if __name__ == \"__main__\": main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
